{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bed4d-0f1a-4dfc-a234-fd2a3c400be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this program compares 2 sentences using GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e18bbdf-f6d4-481e-ba91-a05fb63ec0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe40d5e3-af6f-4b31-bf72-d4df2d1b461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK data if not already available\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a127b1-7f6a-4cd6-88fb-48b5ecc20efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe model\n",
    "def load_glove_model(glove_file):\n",
    "    glove_model = {}\n",
    "    with open(glove_file, 'r', encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            parts = line.split()\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove_model[word] = vector\n",
    "    return glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c131b36-326b-4877-9395-28818bb07025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to GloVe file (update this path if necessary)\n",
    "glove_file = \"glove.6B.50d.txt\"  # Ensure this file is downloaded and in your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed87fe8d-bfd9-4859-9bac-4bc409815ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = load_glove_model(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa19cc6d-c9fd-4777-a31c-2a6c0b527ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences\n",
    "sentences = [\n",
    "    \"I love learning about natural language processing\",\n",
    "    \"Natural language processing is an interesting field\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cad8221-089b-4e38-9bab-7d352099a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and preprocess sentences\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa7e4072-7726-408f-85cb-918502433c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = [preprocess(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc82e0ab-363a-4200-9f67-5aef5ab59efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: ['love', 'learning', 'natural', 'language', 'processing']\n",
      "Sentence 2: ['natural', 'language', 'processing', 'interesting', 'field']\n"
     ]
    }
   ],
   "source": [
    "# Display tokenized sentences\n",
    "for i, sentence in enumerate(tokenized_sentences):\n",
    "    print(f\"Sentence {i+1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ed07f4-3da9-48a8-9671-2cd054929b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document vectors by averaging GloVe word vectors\n",
    "def get_document_vector(tokens, glove_model):\n",
    "    vectors = [glove_model[word] for word in tokens if word in glove_model]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(50)  # GloVe vector size is 50 in this example\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca2567e-8d41-4d64-8873-348ed6e8cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = np.array([get_document_vector(sentence, glove_model) for sentence in tokenized_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "268d4250-6bc3-477e-8084-a10fb2e5a7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Vectors:\n",
      "Document 1: [ 1.7883986e-02  2.9240599e-01 -5.7254601e-01  2.5844589e-01\n",
      "  1.9007158e-01  3.6271521e-01 -2.1979800e-01 -5.5567992e-01\n",
      "  2.1779780e-01  6.1582196e-01  4.2859596e-01  3.5063276e-01\n",
      "  6.5611458e-01 -2.9131359e-01  1.8484604e-02 -5.2832998e-02\n",
      " -4.1074790e-02  4.7943601e-01  2.5839776e-01 -1.5840261e-01\n",
      "  1.6872200e-01  3.2295603e-01  6.2635005e-02  2.2671600e-01\n",
      "  9.0142602e-01 -9.1687793e-01 -4.9397999e-01 -3.4035799e-01\n",
      "  4.8226780e-01 -2.4913999e-01  3.2433000e+00 -3.2932001e-01\n",
      " -1.9281340e-01 -5.4604995e-01  2.7461398e-02  2.5648379e-01\n",
      " -4.3896002e-01  1.1380200e-01  1.3171200e-01  1.8946400e-01\n",
      "  2.3575859e-01 -1.2999800e-01  8.2562000e-02  3.3298001e-01\n",
      " -2.4019957e-03  1.2613200e-01  4.9065280e-01  2.1041620e-01\n",
      " -1.1486460e-01  1.2634361e-01]\n",
      "Document 2: [ 0.07218198  0.19189802 -0.42330605  0.6188019   0.32378358  0.084892\n",
      " -0.436068   -0.515512    0.292756    0.36807603  0.267754    0.09725277\n",
      "  0.5980954  -0.060868   -0.02761139 -0.02483679  0.293806    0.282344\n",
      " -0.16945142 -0.43164802  0.0743946  -0.142364    0.0788584   0.00898401\n",
      "  0.617373   -0.816796   -0.43675    -0.02254399  0.49460596 -0.21695402\n",
      "  3.09906    -0.6014856  -0.04648941 -0.80621797  0.1283914   0.366134\n",
      " -0.44393     0.583206    0.048474    0.36699     0.21479937  0.075994\n",
      "  0.0479704   0.454602   -0.1541472   0.208792    0.508896    0.6193822\n",
      " -0.172639    0.08582742]\n"
     ]
    }
   ],
   "source": [
    "# Print document vectors\n",
    "print(\"\\nDocument Vectors:\")\n",
    "for i, vector in enumerate(doc_vectors):\n",
    "    print(f\"Document {i+1}: {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "600755ee-6ed6-4a32-a6ed-f080d6fc1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity\n",
    "similarity = cosine_similarity(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14d11d1c-52d2-4a94-af14-88429b66cbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarity:\n",
      "[[0.9999999  0.9358847 ]\n",
      " [0.9358847  0.99999994]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCosine Similarity:\")\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71a9a5-7440-4d3b-a027-538913ed5c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
