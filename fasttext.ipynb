{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a88495-d089-4a7b-a1b7-4b5fe5e72ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import FastText\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.data import find\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd633643-b2d2-4c9a-8e2b-73ede9449078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data if not already available\n",
    "try:\n",
    "    find('corpora/stopwords.zip')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e927d7f-d14a-4ff3-8362-c2e42f473498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences\n",
    "sentences = [\n",
    "    \"I love learning about natural language processing\",\n",
    "    \"Natural language processing is an interesting field\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b9fd0b-6410-40da-9a57-b811fc7a998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and preprocess sentences\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a08d0268-92de-4bfe-bb00-aa0520c8c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = [preprocess(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc1cf308-2756-4a9a-a6ca-878f03ced426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: ['love', 'learning', 'natural', 'language', 'processing']\n",
      "Sentence 2: ['natural', 'language', 'processing', 'interesting', 'field']\n"
     ]
    }
   ],
   "source": [
    "# Display tokenized sentences\n",
    "for i, sentence in enumerate(tokenized_sentences):\n",
    "    print(f\"Sentence {i+1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca0a3268-8883-4559-8dd3-670dfd8c973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FastText model for word embeddings\n",
    "model = FastText(sentences=tokenized_sentences, vector_size=50, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c89fd8b-bfe5-4b18-b94f-33dcbd6fe2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word vectors for each word in the vocabulary\n",
    "word_vectors = model.wv\n",
    "vocab = list(word_vectors.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08b1af96-a445-4802-8456-8b00afccc2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Vectors:\n",
      "processing: [-1.4125750e-03  2.5246246e-03  4.3762542e-04  1.5069450e-03\n",
      "  1.2998371e-03  3.4674790e-03 -1.4368900e-03  2.9371914e-03\n",
      " -2.4109876e-03  3.3887534e-04 -5.9384544e-04 -4.2074872e-04\n",
      " -3.4072454e-04 -6.3888740e-04  8.5927331e-04 -2.2283827e-03\n",
      "  1.5533551e-03 -1.8594170e-04  2.9580118e-04 -3.2064372e-03\n",
      "  3.5882583e-03  1.7079883e-03 -2.3575849e-03  1.7934639e-03\n",
      "  2.6873202e-04  3.1212226e-03  1.5573500e-03  9.0156816e-04\n",
      " -3.1312986e-04  2.2482355e-04 -3.7807488e-04 -1.0531490e-03\n",
      "  2.8874140e-04  1.7811084e-03 -2.1276380e-04 -1.5895528e-03\n",
      "  5.3072785e-04  2.9739205e-04  9.6521614e-04  2.9506106e-03\n",
      "  3.3989849e-03 -2.0648264e-03  1.8246549e-03  9.3141251e-05\n",
      " -3.4122440e-04  1.2844171e-03 -3.6812918e-03 -9.8966528e-04\n",
      "  1.7976073e-03 -1.1527844e-05]\n",
      "language: [-4.6082996e-03  3.7044389e-03  5.6315638e-04 -3.9709252e-03\n",
      " -3.2009007e-03  2.5712312e-03 -4.0966831e-04 -4.3883172e-04\n",
      " -2.2495789e-03 -1.6280501e-05  1.6985426e-03 -3.5934447e-04\n",
      "  1.4138073e-04 -6.4289263e-05  3.4623642e-03  1.4596172e-03\n",
      "  7.0384820e-04  5.2163485e-03  2.9829593e-04 -9.6265791e-04\n",
      " -8.7868211e-06 -4.3291580e-05 -1.8387608e-03  3.0987798e-03\n",
      " -1.2574140e-04 -5.5196439e-04 -4.7505698e-03 -2.6363577e-03\n",
      "  3.3292426e-03 -1.4413322e-03  4.1292314e-03  1.0635664e-03\n",
      "  9.7609492e-04  9.4114564e-04 -2.2912116e-03 -1.6690844e-03\n",
      "  1.7849370e-03  1.0723942e-04 -3.4972336e-03  3.1441257e-03\n",
      " -1.2532605e-03  3.4677745e-03  2.9332266e-04  1.5699766e-03\n",
      "  2.4456929e-03 -3.6042943e-04  1.4594481e-03 -2.1173123e-03\n",
      " -7.5296505e-04  1.7831660e-03]\n",
      "natural: [-1.83653086e-03 -7.92178616e-04  8.41024448e-04 -7.99614500e-05\n",
      "  4.31315647e-03 -2.54354649e-03  3.92113999e-03  2.41981517e-03\n",
      " -5.51144476e-04  1.67744525e-03 -2.00364715e-03 -1.34483876e-03\n",
      "  9.37047880e-04  1.75029482e-03  1.91295508e-03 -2.17207460e-04\n",
      " -2.11828272e-03  1.87051739e-03 -2.43358593e-03 -4.77276422e-04\n",
      " -6.93423135e-05  3.13379127e-03 -1.69234048e-03 -2.63962918e-03\n",
      "  4.99394815e-03  1.88927894e-04 -4.31706198e-03 -1.62894151e-03\n",
      " -1.21037941e-03 -1.02065016e-04  4.04642057e-03  2.33078608e-03\n",
      " -4.14296752e-04 -4.85069002e-04  3.71246220e-04 -3.18654114e-04\n",
      "  4.21410426e-04 -1.73559631e-04 -4.14209877e-04  8.38259642e-04\n",
      "  1.83470396e-03  7.24663958e-04 -5.43148443e-03  9.45092703e-04\n",
      " -1.25669304e-03 -2.17915932e-03 -2.12232210e-03 -1.76514324e-03\n",
      "  1.28280779e-03  5.13017061e-04]\n",
      "field: [-1.6753586e-03 -3.6907266e-03  1.2811546e-03 -2.5358636e-04\n",
      "  1.6615912e-03  5.5720699e-03 -3.7328282e-03 -6.4655027e-04\n",
      " -2.0513697e-04  3.6061753e-03 -7.7568687e-04  3.4409750e-03\n",
      "  1.0856957e-03  2.0969654e-03  1.7542999e-03 -3.0760323e-03\n",
      "  2.6579136e-03 -2.5028186e-03  1.3700168e-03  4.5565641e-04\n",
      " -5.5552069e-03 -1.1260702e-04 -2.3910063e-03  3.5193670e-03\n",
      "  5.5824337e-04  1.9634450e-03  2.2007941e-04 -2.9739940e-03\n",
      "  2.5243054e-03 -3.2778089e-03 -2.6965539e-03 -4.7732759e-04\n",
      "  3.1230792e-03 -1.5516892e-03 -4.5989025e-03  1.6644796e-03\n",
      " -5.1715346e-03  7.1631745e-04 -1.6313237e-03 -4.0517517e-04\n",
      "  2.0329761e-03 -2.5803514e-03 -1.3247698e-03  2.9981916e-03\n",
      " -8.9739065e-04 -3.7541392e-03  1.3054310e-03 -1.8928185e-03\n",
      "  1.6757349e-05  9.7873888e-04]\n",
      "interesting: [-4.5209061e-03  2.1994764e-03 -2.3107140e-03  6.3899462e-04\n",
      "  6.0858561e-05  2.0005025e-03 -2.5734676e-03 -1.2621809e-04\n",
      " -2.2550223e-04  2.0338728e-03 -3.2225791e-05 -7.0748676e-04\n",
      "  9.3642075e-04  4.7567798e-04 -2.4502852e-03  6.5317674e-04\n",
      " -8.5933332e-04 -1.1396612e-03 -1.1526860e-03 -9.3574135e-04\n",
      " -1.9274921e-03 -1.1842122e-03  1.2676867e-03 -6.5894227e-04\n",
      "  2.7641093e-03  8.9091033e-04  8.3406229e-04 -1.2829541e-03\n",
      "  2.8824032e-04  2.6236873e-03  1.3835030e-03 -3.0847188e-04\n",
      " -1.8531716e-03  1.7187140e-03  1.0962344e-03  5.5475358e-04\n",
      "  2.0818952e-03 -2.8338158e-03  6.5261807e-04  3.8171868e-04\n",
      " -3.6772675e-05 -1.5669435e-04 -9.7691070e-04  1.7024305e-03\n",
      " -8.6966186e-04 -1.7310795e-04  1.2726595e-03 -1.2643377e-03\n",
      " -9.3251106e-04  8.1386702e-04]\n",
      "learning: [-9.0671593e-04 -2.2432633e-04 -7.8091054e-04 -2.5647278e-03\n",
      " -2.1715167e-03  1.0949203e-03  2.0888806e-03 -1.0987729e-03\n",
      " -3.9985650e-03  1.2817449e-03  5.7589990e-04 -1.4667021e-03\n",
      "  6.4052106e-04  1.9244953e-03  6.1472901e-04 -5.6716410e-04\n",
      "  2.1646831e-03 -4.2322525e-04 -8.6920144e-04  4.0003476e-03\n",
      "  1.6453671e-03 -6.0643023e-04 -2.9671071e-03  2.5215242e-03\n",
      "  1.5332884e-03 -1.7094940e-03 -1.7770086e-03  2.9036140e-03\n",
      " -1.3844683e-03  4.9006492e-03  3.2605084e-03  2.2089565e-03\n",
      " -3.0667810e-03  1.0685154e-03 -7.6237333e-04 -1.6433552e-03\n",
      " -2.5746334e-04  4.2393376e-04  4.6180976e-03  4.8220092e-03\n",
      "  2.6786218e-03  6.4703304e-04  4.0989420e-03 -4.0856950e-05\n",
      " -9.3717774e-04 -6.1758398e-04 -3.3428103e-03 -4.0683877e-03\n",
      " -1.8923359e-03  4.0107354e-04]\n",
      "love: [ 1.7015055e-04  3.2654912e-03 -4.3467022e-03 -1.7325252e-03\n",
      " -4.3999446e-03 -3.8207553e-03 -1.2222297e-03 -7.1135798e-04\n",
      "  7.8455387e-03 -6.8471213e-03 -1.9308891e-03 -4.1394499e-03\n",
      " -2.0388903e-03 -1.3763194e-03 -2.8880895e-03 -2.0455213e-03\n",
      "  1.2534306e-03 -1.6251956e-04 -3.0695421e-03  1.7313235e-03\n",
      "  5.5678184e-03  1.9528429e-03  1.5591666e-03  1.2839324e-03\n",
      " -5.5347113e-03  3.5880348e-03  1.3251865e-04 -6.6806893e-03\n",
      "  1.4638894e-03  4.4527388e-04 -2.1417465e-03 -4.2535607e-03\n",
      " -5.8999378e-03  7.5062360e-03 -2.9192888e-03 -7.9439266e-04\n",
      " -6.4783619e-04 -3.3111118e-03 -3.3311828e-03 -1.5197140e-03\n",
      " -4.1656452e-03  7.1060229e-03  5.5959220e-03  3.2136033e-03\n",
      " -9.1954556e-05 -1.5539690e-03 -9.0931804e-04 -9.4620121e-04\n",
      " -2.6489142e-03  2.8598877e-03]\n"
     ]
    }
   ],
   "source": [
    "# Print word vectors for each word in the vocabulary\n",
    "print(\"\\nWord Vectors:\")\n",
    "for word in vocab:\n",
    "    print(f\"{word}: {word_vectors[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24599972-b0a0-48a5-a2e6-c24b2505a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document vectors by averaging word vectors\n",
    "def get_document_vector(tokens):\n",
    "    vectors = [word_vectors[word] for word in tokens if word in word_vectors]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(word_vectors.vector_size)\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb500a3f-4c88-432d-8ed9-4825ee148449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Vectors:\n",
      "Document 1: [-1.7187942e-03  1.6956100e-03 -6.5716135e-04 -1.3682388e-03\n",
      " -8.3187374e-04  1.5386581e-04  5.8824650e-04  6.2160881e-04\n",
      " -2.7294751e-04 -7.1306730e-04 -4.5078783e-04 -1.5462168e-03\n",
      " -1.3213302e-04  3.1905880e-04  7.9224643e-04 -7.1973167e-04\n",
      "  7.1140687e-04  1.2630358e-03 -1.1556464e-03  2.1705995e-04\n",
      "  2.1446631e-03  1.2289801e-03 -1.4593254e-03  1.2116141e-03\n",
      "  2.2710320e-04  9.2734536e-04 -1.8309545e-03 -1.4281613e-03\n",
      "  3.7703087e-04  8.0546987e-04  1.7832678e-03  5.9319871e-05\n",
      " -1.6232359e-03  2.1623871e-03 -1.1628784e-03 -1.2030079e-03\n",
      "  3.6635515e-04 -5.3122122e-04 -3.3186251e-04  2.0470582e-03\n",
      "  4.9868098e-04  1.9761336e-03  1.2762714e-03  1.1561913e-03\n",
      " -3.6271365e-05 -6.8534492e-04 -1.7192587e-03 -1.9773419e-03\n",
      " -4.4275998e-04  1.1091233e-03]\n",
      "Document 2: [-2.81073409e-03  7.89127022e-04  1.62449389e-04 -4.31706663e-04\n",
      "  8.26908567e-04  2.21354747e-03 -8.46342824e-04  8.29081342e-04\n",
      " -1.12846994e-03  1.52801757e-03 -3.41372506e-04  1.21711244e-04\n",
      "  5.51964040e-04  7.23952311e-04  1.10772136e-03 -6.81765727e-04\n",
      "  3.87500186e-04  6.51688781e-04 -3.24431603e-04 -1.02529128e-03\n",
      " -7.94513966e-04  7.00333738e-04 -1.40240113e-03  1.02260779e-03\n",
      "  1.69185828e-03  1.12250831e-03 -1.29122811e-03 -1.52413582e-03\n",
      "  9.23655753e-04 -3.94539064e-04  1.29690522e-03  3.11080774e-04\n",
      "  4.24089434e-04  4.80842020e-04 -1.12707948e-03 -2.71611672e-04\n",
      " -7.05128550e-05 -3.77285294e-04 -7.84986652e-04  1.38190784e-03\n",
      "  1.19532633e-03 -1.21886747e-04 -1.12303742e-03  1.46176643e-03\n",
      " -1.83855402e-04 -1.03648379e-03 -3.53215059e-04 -1.60585530e-03\n",
      "  2.82339286e-04  8.15452193e-04]\n"
     ]
    }
   ],
   "source": [
    "doc_vectors = np.array([get_document_vector(sentence) for sentence in tokenized_sentences])\n",
    "\n",
    "# Print document vectors\n",
    "print(\"\\nDocument Vectors:\")\n",
    "for i, vector in enumerate(doc_vectors):\n",
    "    print(f\"Document {i+1}: {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f08113aa-024b-47bb-8f43-d82499070797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity\n",
    "similarity = cosine_similarity(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc30537-3655-4ec7-91d9-77b505530ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarity:\n",
      "[[1.0000001  0.5043084 ]\n",
      " [0.5043084  0.99999994]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCosine Similarity:\")\n",
    "print(similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
