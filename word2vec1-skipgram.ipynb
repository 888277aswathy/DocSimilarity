{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90bbc8-b1d1-43cd-8228-7129b50f4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds document similarity using word2vec - CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b36f05c-7216-4142-b967-4edab2d655d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.data import find\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "160dea87-9ce9-49ce-903c-ccd9af61e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data if not already available\n",
    "try:\n",
    "    find('corpora/stopwords.zip')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb32ccb-8b50-434d-988f-695de940ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences\n",
    "sentences = [\n",
    "    \"I love natural language processing\",\n",
    "    \"Language processing is fascinating\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff8191c-f58e-461a-aee7-46542aea7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and preprocess sentences\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35e1f4b-2e56-40b2-8df8-feed8ed39a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = [preprocess(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3029f0c-3a7c-42e4-bb00-7084d1e8b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "# Use sg=0 for CBOW or sg=1 for Skip-gram\n",
    "model = Word2Vec(sentences=tokenized_sentences, vector_size=50, window=5, sg=0, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "484e354e-2f76-48e4-bfcb-a4ad7d06f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (optional)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f983f9-0c06-47d7-a9be-84410af28030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (optional)\n",
    "# model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23981d5f-c386-42cc-bcab-f12702005cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word vectors for each word in the vocabulary\n",
    "word_vectors = model.wv\n",
    "vocab = list(word_vectors.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8478f4a0-e0c9-400d-804c-3e682416a7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Vectors:\n",
      "processing: [-1.0724545e-03  4.7286271e-04  1.0206699e-02  1.8018546e-02\n",
      " -1.8605899e-02 -1.4233618e-02  1.2917745e-02  1.7945977e-02\n",
      " -1.0030856e-02 -7.5267432e-03  1.4761009e-02 -3.0669428e-03\n",
      " -9.0732267e-03  1.3108104e-02 -9.7203208e-03 -3.6320353e-03\n",
      "  5.7531595e-03  1.9837476e-03 -1.6570430e-02 -1.8897636e-02\n",
      "  1.4623532e-02  1.0140524e-02  1.3515387e-02  1.5257311e-03\n",
      "  1.2701781e-02 -6.8107317e-03 -1.8928028e-03  1.1537147e-02\n",
      " -1.5043275e-02 -7.8722071e-03 -1.5023164e-02 -1.8600845e-03\n",
      "  1.9076237e-02 -1.4638334e-02 -4.6675373e-03 -3.8754821e-03\n",
      "  1.6154874e-02 -1.1861792e-02  9.0324880e-05 -9.5074680e-03\n",
      " -1.9207101e-02  1.0014586e-02 -1.7519170e-02 -8.7836506e-03\n",
      " -7.0199967e-05 -5.9236289e-04 -1.5322480e-02  1.9229487e-02\n",
      "  9.9641159e-03  1.8466286e-02]\n",
      "language: [-0.01631583  0.0089916  -0.00827415  0.00164907  0.01699724 -0.00892435\n",
      "  0.009035   -0.01357392 -0.00709698  0.01879702 -0.00315531  0.00064274\n",
      " -0.00828126 -0.01536538 -0.00301602  0.00493959 -0.00177605  0.01106732\n",
      " -0.00548595  0.00452013  0.01091159  0.01669191 -0.00290748 -0.01841629\n",
      "  0.0087411   0.00114357  0.01488382 -0.00162657 -0.00527683 -0.01750602\n",
      " -0.00171311  0.00565313  0.01080286  0.01410531 -0.01140624  0.00371764\n",
      "  0.01217773 -0.0095961  -0.00621452  0.01359526  0.00326295  0.00037983\n",
      "  0.00694727  0.00043555  0.01923765  0.01012121 -0.01783478 -0.01408312\n",
      "  0.00180291  0.01278507]\n",
      "fascinating: [-0.01723938  0.00733148  0.01037977  0.01148388  0.01493384 -0.01233535\n",
      "  0.00221123  0.01209456 -0.0056801  -0.01234705 -0.00082045 -0.0167379\n",
      " -0.01120002  0.01420908  0.00670508  0.01445134  0.01360049  0.01506148\n",
      " -0.00757831 -0.00112361  0.00469675 -0.00903806  0.01677746 -0.01971633\n",
      "  0.01352928  0.00582883 -0.00986566  0.00879638 -0.00347915  0.01342277\n",
      "  0.0199297  -0.00872489 -0.00119868 -0.01139127  0.00770164  0.00557325\n",
      "  0.01378215  0.01220219  0.01907699  0.01854683  0.01579614 -0.01397901\n",
      " -0.01831173 -0.00071151 -0.00619968  0.01578863  0.01187715 -0.00309133\n",
      "  0.00302193  0.00358008]\n",
      "natural: [ 1.56351421e-02 -1.90203730e-02 -4.11062239e-04  6.93839323e-03\n",
      " -1.87794445e-03  1.67635437e-02  1.80215668e-02  1.30730132e-02\n",
      " -1.42324204e-03  1.54208085e-02 -1.70686692e-02  6.41421322e-03\n",
      " -9.27599426e-03 -1.01779103e-02  7.17923651e-03  1.07406788e-02\n",
      "  1.55390287e-02 -1.15330126e-02  1.48667218e-02  1.32509926e-02\n",
      " -7.41960062e-03 -1.74912829e-02  1.08749345e-02  1.30195115e-02\n",
      " -1.57510047e-03 -1.34197120e-02 -1.41718509e-02 -4.99412045e-03\n",
      "  1.02865072e-02 -7.33047491e-03 -1.87401194e-02  7.65347946e-03\n",
      "  9.76895820e-03 -1.28571270e-02  2.41711619e-03 -4.14975407e-03\n",
      "  4.88066689e-05 -1.97670180e-02  5.38400887e-03 -9.50021297e-03\n",
      "  2.17529293e-03 -3.15244915e-03  4.39334614e-03 -1.57631524e-02\n",
      " -5.43436781e-03  5.32639725e-03  1.06933638e-02 -4.78302967e-03\n",
      " -1.90201886e-02  9.01175756e-03]\n",
      "love: [ 0.00018913  0.00615464 -0.01362529 -0.00275093  0.01533716  0.01469282\n",
      " -0.00734659  0.0052854  -0.01663426  0.01241097 -0.00927464 -0.00632821\n",
      "  0.01862271  0.00174677  0.01498141 -0.01214813  0.01032101  0.01984565\n",
      " -0.01691478 -0.01027138 -0.01412967 -0.0097253  -0.00755713 -0.0170724\n",
      "  0.01591121 -0.00968788  0.01684723  0.01052514 -0.01310005  0.00791574\n",
      "  0.0109403  -0.01485307 -0.01481144 -0.00495046 -0.01725145 -0.00316314\n",
      " -0.00080687  0.00659937  0.00288376 -0.00176284 -0.01118812  0.00346073\n",
      " -0.00179474  0.01358738  0.00794718  0.00905894  0.00286861 -0.00539971\n",
      " -0.00873363 -0.00206415]\n"
     ]
    }
   ],
   "source": [
    "# Print word vectors for each word in the vocabulary\n",
    "print(\"\\nWord Vectors:\")\n",
    "for word in vocab:\n",
    "    print(f\"{word}: {word_vectors[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd8ee951-305d-4a01-8c9d-72d78a7619f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document vectors by averaging word vectors\n",
    "def get_document_vector(tokens):\n",
    "    vectors = [word_vectors[word] for word in tokens if word in word_vectors]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(word_vectors.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "doc_vectors = np.array([get_document_vector(sentence) for sentence in tokenized_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19af2281-4ccc-4ac3-b301-8e68a2aab645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Vectors:\n",
      "Document 1: [-3.9100490e-04 -8.5031858e-04 -3.0259513e-03  5.9637697e-03\n",
      "  2.9626396e-03  2.0745976e-03  8.1569292e-03  5.6826184e-03\n",
      " -8.7963343e-03  9.7755129e-03 -3.6844027e-03 -5.8454985e-04\n",
      " -2.0019419e-03 -2.6721025e-03  2.3560759e-03 -2.4973007e-05\n",
      "  7.4592866e-03  5.3409259e-03 -6.0261115e-03 -2.8494739e-03\n",
      "  9.9646137e-04 -9.6039148e-05  3.4814281e-03 -5.2358601e-03\n",
      "  8.9447489e-03 -7.1936878e-03  3.9165975e-03  3.8604005e-03\n",
      " -5.7834121e-03 -6.1982395e-03 -6.1340248e-03 -8.5163780e-04\n",
      "  6.2091537e-03 -4.5851525e-03 -7.7270283e-03 -1.8676852e-03\n",
      "  6.8936357e-03 -8.6563863e-03  5.3589337e-04 -1.7938162e-03\n",
      " -6.2392433e-03  2.6756758e-03 -1.9933234e-03 -2.6309665e-03\n",
      "  5.4200664e-03  5.9785466e-03 -4.8988215e-03 -1.2590936e-03\n",
      " -3.9966968e-03  9.5497407e-03]\n",
      "Document 2: [-1.1542555e-02  5.5986452e-03  4.1041048e-03  1.0383832e-02\n",
      "  4.4417260e-03 -1.1831108e-02  8.0546578e-03  5.4888739e-03\n",
      " -7.6026451e-03 -3.5892427e-04  3.5950860e-03 -6.3873655e-03\n",
      " -9.5181698e-03  3.9839349e-03 -2.0104193e-03  5.2529643e-03\n",
      "  5.8591999e-03  9.3708513e-03 -9.8782303e-03 -5.1670391e-03\n",
      "  1.0077291e-02  5.9314556e-03  9.1284560e-03 -1.2202294e-02\n",
      "  1.1657390e-02  5.3890672e-05  1.0417834e-03  6.2356521e-03\n",
      " -7.9330839e-03 -3.9851521e-03  1.0644738e-03 -1.6439484e-03\n",
      "  9.5601398e-03 -3.9747651e-03 -2.7907118e-03  1.8051369e-03\n",
      "  1.4038253e-02 -3.0852342e-03  4.3175989e-03  7.5448751e-03\n",
      " -4.9337745e-05 -1.1948626e-03 -9.6278749e-03 -3.0198668e-03\n",
      "  4.3225903e-03  8.4391600e-03 -7.0933700e-03  6.8501331e-04\n",
      "  4.9296515e-03  1.1610479e-02]\n"
     ]
    }
   ],
   "source": [
    "# Print document vectors\n",
    "print(\"\\nDocument Vectors:\")\n",
    "for i, vector in enumerate(doc_vectors):\n",
    "    print(f\"Document {i+1}: {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd5d65c2-f726-46c0-8efb-91cd8ae451ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity\n",
    "similarity = cosine_similarity(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c28437ec-ba52-4e94-bbd5-e64c933b7aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarity:\n",
      "[[0.99999994 0.60899895]\n",
      " [0.60899895 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCosine Similarity:\")\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934eafe8-b82d-4062-bda9-d815ff1a206e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
